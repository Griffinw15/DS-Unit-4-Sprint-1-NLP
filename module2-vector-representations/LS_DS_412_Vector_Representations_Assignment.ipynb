{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientistÂ   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "df = pd.read_csv(\"./data/job_listings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['descriptions'] = df['description'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(html):\n",
    "    html = html.lstrip('b\"\\'').rstrip('\"\\'')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Job Requirements:\\nConceptual understanding in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Job Description\\n\\nAs a Data Scientist 1, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>As a Data Scientist you will be working on con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>$4,969 - $6,756 a monthContractUnder the gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Location: USA \\xe2\\x80\\x93 multiple locations\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientistÂ    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                        descriptions  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                                   description_clean  \n",
       "0  Job Requirements:\\nConceptual understanding in...  \n",
       "1  Job Description\\n\\nAs a Data Scientist 1, you ...  \n",
       "2  As a Data Scientist you will be working on con...  \n",
       "3  $4,969 - $6,756 a monthContractUnder the gener...  \n",
       "4  Location: USA \\xe2\\x80\\x93 multiple locations\\...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description_clean'] = df['descriptions'].apply(make_soup)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP_WORDS = nlp.Defaults.stop_words.union([\"coffee\",\"it's\", \"i'm\", \"i've\", \"got\", \"it\", \" \", \"it.\", \"place\", \"this\", \"  \", \"\", \"   \", \"    \", \" -\", \"-\", \"  -\", \"s\", \" s\", \"s \", \" s \", \"coffee.\", \"shop\", \"come\", \"don't\", \"time\", \"austin\", \"people\", \"coffee,\", \"work\", \"tea\", \"iced\", \"definitely\", \"drink\", \"try\", \"ordered\", \"you're\", \"didn't\", \"&\", \"know\", \"want\", \"came\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    doc = nlp(text.strip())\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [job, requirements:\\nconceptual, understanding...\n",
       "1      [job, description\\n\\nas, data, scientist, 1, h...\n",
       "2      [data, scientist, working, consulting, busines...\n",
       "3      [$, 4,969, $, 6,756, monthcontractunder, gener...\n",
       "4      [location, usa, \\xe2\\x80\\x93, multiple, locati...\n",
       "                             ...                        \n",
       "421    [us:\\nwant, fantastic, fun, startup, that\\xe2\\...\n",
       "422    [internshipat, uber, ignite, opportunity, sett...\n",
       "423    [$, 200,000, $, 350,000, yeara, million, peopl...\n",
       "424    [senior, data, scientist\\njob, description\\n\\n...\n",
       "425    [cerner, intelligence, new, innovative, organi...\n",
       "Name: description_clean, Length: 426, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description_clean'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "#vect = CountVectorizer(stop_words='english', min_df=2, max_df=.95, ngram_range(1,2))\n",
    "\n",
    "vect.fit(df['description_clean'])\n",
    "\n",
    "dtm = vect.transform(df['description_clean'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2019</th>\n",
       "      <th>40</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>xa6</th>\n",
       "      <th>xae</th>\n",
       "      <th>xb7</th>\n",
       "      <th>xbb</th>\n",
       "      <th>xc2</th>\n",
       "      <th>xe2</th>\n",
       "      <th>xef</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  100  2019  40  abilities  ability  able  academic  access  ...  \\\n",
       "0    0   0    0     0   0          0        1     0         0       0  ...   \n",
       "1    0   0    0     0   0          0        1     0         0       0  ...   \n",
       "2    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "3    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "4    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "\n",
       "   xa6  xae  xb7  xbb  xc2  xe2  xef  year  years  york  \n",
       "0    0    0    0    0    1    0    0     0      0     0  \n",
       "1    2    0    0    0    0    8    0     1      0     0  \n",
       "2    0    0    0    0    0    0    0     0      0     0  \n",
       "3    0    0    0    0    0    0    0     1      0     0  \n",
       "4    0    0    0    0    0    1    0     0      1     0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boilerplate count func. to help w text\n",
    "from collections import Counter\n",
    "\n",
    "def count(docs):\n",
    "\n",
    "        word_counts = Counter()\n",
    "        appears_in = Counter()\n",
    "        \n",
    "        total_docs = len(docs)\n",
    "\n",
    "        for doc in docs:\n",
    "            word_counts.update(doc)\n",
    "            appears_in.update(set(doc))\n",
    "\n",
    "        temp = zip(word_counts.keys(), word_counts.values())\n",
    "        \n",
    "        wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "        total = wc['count'].sum()\n",
    "\n",
    "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "        wc = wc.sort_values(by='rank')\n",
    "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "        t2 = zip(appears_in.keys(), appears_in.values())\n",
    "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "        wc = ac.merge(wc, on='word')\n",
    "\n",
    "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "        return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Function\n",
    "text_data = count(df['description_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import squarify\n",
    "text_data_top20 = text_data[text_data['rank'] <= 20]\n",
    "\n",
    "squarify.plot(sizes=text_data_top20['pct_total'], label=text_data_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 employees</th>\n",
       "      <th>10</th>\n",
       "      <th>10 years</th>\n",
       "      <th>100</th>\n",
       "      <th>100 000</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>12 months</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>years relevant</th>\n",
       "      <th>years work</th>\n",
       "      <th>years working</th>\n",
       "      <th>years xe2</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>york city</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zf</th>\n",
       "      <th>zillow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000 employees   10  10 years  100  100 000   11   12  12 months   15  \\\n",
       "0  0.0            0.0  0.0       0.0  0.0      0.0  0.0  0.0        0.0  0.0   \n",
       "1  0.0            0.0  0.0       0.0  0.0      0.0  0.0  0.0        0.0  0.0   \n",
       "2  0.0            0.0  0.0       0.0  0.0      0.0  0.0  0.0        0.0  0.0   \n",
       "3  0.0            0.0  0.0       0.0  0.0      0.0  0.0  0.0        0.0  0.0   \n",
       "4  0.0            0.0  0.0       0.0  0.0      0.0  0.0  0.0        0.0  0.0   \n",
       "\n",
       "   ...  years relevant  years work  years working  years xe2  yes  york  \\\n",
       "0  ...             0.0         0.0            0.0        0.0  0.0   0.0   \n",
       "1  ...             0.0         0.0            0.0        0.0  0.0   0.0   \n",
       "2  ...             0.0         0.0            0.0        0.0  0.0   0.0   \n",
       "3  ...             0.0         0.0            0.0        0.0  0.0   0.0   \n",
       "4  ...             0.0         0.0            0.0        0.0  0.0   0.0   \n",
       "\n",
       "   york city  yrs   zf  zillow  \n",
       "0        0.0  0.0  0.0     0.0  \n",
       "1        0.0  0.0  0.0     0.0  \n",
       "2        0.0  0.0  0.0     0.0  \n",
       "3        0.0  0.0  0.0     0.0  \n",
       "4        0.0  0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Similiar to fit_predict\n",
    "dtm = tfidf.fit_transform(df['description_clean'])\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    \n",
    "    doc = nlp(document)\n",
    "    \n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$</th>\n",
       "      <th>$ 100,000</th>\n",
       "      <th>$ 300</th>\n",
       "      <th>$ 40</th>\n",
       "      <th>+</th>\n",
       "      <th>+ city</th>\n",
       "      <th>+ year</th>\n",
       "      <th>+ years\\xe2\\x80\\x99</th>\n",
       "      <th>.\\n\\nabout</th>\n",
       "      <th>.\\n\\nabout role\\n\\nas</th>\n",
       "      <th>...</th>\n",
       "      <th>you\\xe2\\x80\\x99ll partner</th>\n",
       "      <th>you\\xe2\\x80\\x99ll work</th>\n",
       "      <th>you\\xe2\\x80\\x99re</th>\n",
       "      <th>you\\xe2\\x80\\x99re look</th>\n",
       "      <th>you\\xe2\\x80\\x99re ready</th>\n",
       "      <th>you\\xe2\\x80\\x99ve</th>\n",
       "      <th>you\\xe2\\x80\\x99ve work</th>\n",
       "      <th>yrs</th>\n",
       "      <th>|</th>\n",
       "      <th>||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 10738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          $  $ 100,000  $ 300  $ 40         +  + city    + year  \\\n",
       "0  0.000000        0.0    0.0   0.0  0.000000     0.0  0.000000   \n",
       "1  0.000000        0.0    0.0   0.0  0.026648     0.0  0.029098   \n",
       "2  0.000000        0.0    0.0   0.0  0.000000     0.0  0.000000   \n",
       "3  0.233208        0.0    0.0   0.0  0.000000     0.0  0.000000   \n",
       "4  0.000000        0.0    0.0   0.0  0.133049     0.0  0.145279   \n",
       "\n",
       "   + years\\xe2\\x80\\x99  .\\n\\nabout  .\\n\\nabout role\\n\\nas  ...  \\\n",
       "0                  0.0         0.0                    0.0  ...   \n",
       "1                  0.0         0.0                    0.0  ...   \n",
       "2                  0.0         0.0                    0.0  ...   \n",
       "3                  0.0         0.0                    0.0  ...   \n",
       "4                  0.0         0.0                    0.0  ...   \n",
       "\n",
       "   you\\xe2\\x80\\x99ll partner  you\\xe2\\x80\\x99ll work  you\\xe2\\x80\\x99re  \\\n",
       "0                        0.0                     0.0                0.0   \n",
       "1                        0.0                     0.0                0.0   \n",
       "2                        0.0                     0.0                0.0   \n",
       "3                        0.0                     0.0                0.0   \n",
       "4                        0.0                     0.0                0.0   \n",
       "\n",
       "   you\\xe2\\x80\\x99re look  you\\xe2\\x80\\x99re ready  you\\xe2\\x80\\x99ve  \\\n",
       "0                     0.0                      0.0                0.0   \n",
       "1                     0.0                      0.0                0.0   \n",
       "2                     0.0                      0.0                0.0   \n",
       "3                     0.0                      0.0                0.0   \n",
       "4                     0.0                      0.0                0.0   \n",
       "\n",
       "   you\\xe2\\x80\\x99ve work  yrs    |   ||  \n",
       "0                     0.0  0.0  0.0  0.0  \n",
       "1                     0.0  0.0  0.0  0.0  \n",
       "2                     0.0  0.0  0.0  0.0  \n",
       "3                     0.0  0.0  0.0  0.0  \n",
       "4                     0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 10738 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning Parameters\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,2),\n",
    "                        max_df=.97,\n",
    "                        min_df=3,\n",
    "                        tokenizer=tokenize)\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "dtm = tfidf.fit_transform(df['description_clean']) # Similiar to fit_predict\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.29624578, 1.3018282 , 1.33053148, 1.33510658]]),\n",
       " array([[  0, 115, 274, 403, 338]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.25373899, 1.25373899, 1.26567616, 1.27014985]]),\n",
       " array([[403, 315, 207, 325, 285]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query Using kneighbors \n",
    "nn.kneighbors([dtm.iloc[403]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description_clean'][0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About Us\\\\nInterested in working for a human-centered technology company that prides itself on using modern tools and technologies? Want to be surrounded by intensely curious and innovative thinkers?\\\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description_clean'][403][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_role_desc = [\"\"\"\n",
    "Data driven individual with a knack for analytics. Proficient in python, sql, and excel. Ability to communicate with technical and non technical shareholders.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for Sim of Random doc to BBC\n",
    "new = tfidf.transform(ideal_role_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.31878782, 1.3268761 , 1.33482018, 1.33721767, 1.33773852]]),\n",
       " array([[403, 417,  56,   0,  59]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About Us\\\\nInterested in working for a human-centered technology company that prides itself on using modern tools and technologies? Want to be surrounded by intensely curious and innovative thinkers?\\\\n\\\\nSeeking to solve complex technical challenges by building products that work for people, meet and exceed the needs of businesses, and work elegantly and efficiently?\\\\n\\\\nModeling ourselves after the 1904 World\\\\xe2\\\\x80\\\\x99s Fair, which brought innovation to the region, 1904labs is seeking top technical talent in St. Louis to bring innovation and creativity to our clients.\\\\n\\\\nOur clients consist of Fortune 500 and Global 2000 companies headquartered here in St. Louis. We partner with them on complex projects that range from reimagining and refactoring their existing applications, to helping to envision and build new applications or data streams to operationalize their existing data. Working in a team-based labs model, using our own flavor of #HCDAgile, we strive to work at the cutting edge of technology\\\\xe2\\\\x80\\\\x99s capabilities while solving problems for our clients and their users.\\\\n\\\\nThe Role\\\\nAs a Data Scientist with 1904labs, you will be working with other data scientists, data engineers, and developers to provide analytical services to clients. You will leverage the clients\\\\xe2\\\\x80\\\\x99 data assets to answer business questions using best practices and innovative approaches. This will mean employing various data science tools (Python, apache spark, TensorFlow) and techniques (dimensionality reduction, unsupervised learning, supervised learning) to create and test machine learning algorithms. Once tested and verified you will work with development teams to implement the algorithm as a scalable, hosted service.\\\\n\\\\nWe\\\\xe2\\\\x80\\\\x99re looking for an experienced and creative data scientist who can conceptualize a project from start to finish, identifying the appropriate data and methodologies to use. Our Data Scientists work with open-source machine learning packages and libraries, so this position involves building custom ML/AI utilities from open-source resources in languages such as Python (preferred) and R. In this role, you will own and share technical solutions with both technical and non-technical stakeholders across multiple teams both internally and with external clients.\\\\n\\\\nResponsibilities\\\\n\\\\nPerform data analysis to understand the right combinations of data to meet outlined objectives\\\\nTranslate client queries into actionable data pulls and help translate outputs into client strategies\\\\nBuild and evaluate predictive modeling & machine learning utilities to produce meaningful outcomes that enable data-led decisions\\\\nTranslate analysis results into actionable insights\\\\nPresent insights to both technical and non-technical audiences\\\\nPartner with internal data scientists, developers, and tech teams to develop new methodologies and utilities\\\\nWork with development teams to implement data science algorithms as scalable, hosted services\\\\n\\\\nYour Skills\\\\nRequirements\\\\n\\\\nBackground in math including linear algebra, statistics, probability, and numerical analysis.\\\\nMachine Learning Analysis: Must be able to execute, evaluate, and apply various models such as logistic regression, random forests/decision tree, nearest neighbor, neural net, support vector machine, an ensemble of multiple models, etc\\\\xe2\\\\x80\\\\xa6\\\\nProgramming: Proficient coding in a language suited for machine learning systems such as Python or R (not reliant on GUI-based systems to execute analysis) for the purpose of cleaning, manipulating, visualizing, and analyzing data\\\\n\\\\nDesired Skills\\\\n\\\\nExperience with software engineering and developing deployable API services\\\\nMust be adaptable and have the drive to learn new technologies and frameworks to support developing client solutions\\\\nUsing browser based interactive computational environments (like Jupyter Notebook) to perform analysis activities and test / evaluate data models and algorithms.\\\\nTools: Spark, Pandas, SciKit-Learn, TensorFlow, Keras, SQL\\\\nCommunication: Must be able to explain analysis process and translate results into actionable insights for both technical and non-technical audiences\\\\nTeamwork: Must be accountable for individual responsibilities while working collaboratively with development and engineering teams to achieve project deliverables\\\\nComfort in an agile development environment (eg. writing stories, participating in workshops, sprint planning and retros)\\\\n\\\\nPerks\\\\n\\\\nBenefits Program (medical, dental, life insurance, 401(k), professional and personal development, PTO)\\\\nInnovation Time - we allow 10% of your time to be devoted to innovation hours. This time can be used to foster individual ideas, personal projects, start up ideas, improve an open source tool or for career advancement and self-education. All during traditional working hours.\\\\nDress Code - we don't have one\\\\n\\\\nThese roles are located in St. Louis, MO. While we would prefer local candidates your location is not the most important factor; please help us understand why you would like to call St. Louis home if you would be relocating.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description_clean'][403]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
